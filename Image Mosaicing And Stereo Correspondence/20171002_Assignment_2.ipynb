{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll no - 20171002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements :-\n",
    "##### Libraries:-\n",
    "* Numpy\n",
    "* os\n",
    "* Python 3.x\n",
    "* scikit-image\n",
    "* matplotlib\n",
    "* math\n",
    "* mpl_toolkits.axes_grid1\n",
    "* OpenCV 3.4.2.16\n",
    "\n",
    "### To run this notebook successfully, please ensure the following steps.\n",
    "* Ensure that all the libraries mentioned above are installed\n",
    "* Ensure that in the current working directory the folder **Camera_calibration_data** and its entire folder structure exists and is maintained. **This is the input data to notebook.**\n",
    "\n",
    "\n",
    "\n",
    "### Note:-\n",
    "* ***If any of the steps are missing/files are missing, then some parts of the code may or may not work***\n",
    "* *The Results folder contains some outputs saved from the script*\n",
    "* It is advised to use the testing machine in \"plugged in\" mode, to avoid core suppression as happens in most modern PCs.\n",
    "* **Results are uploaded on Microsoft OneDrive at this link, `https://1drv.ms/u/s!AriDLlttrVxZjlrTnQkkLt4AYvUr?e=WSQ4kI`**.Please note that this is hosted on IIITH's Google Drive.\n",
    "* Resources are also uploaded in case in they are not uploadable on Moodle under the name `CV Assignment 2/images`, at this link **`https://1drv.ms/u/s!AriDLlttrVxZjj1TSuRgGlHwmlgP?e=lRRqWP`**. If need be, copy the directory to the location of this iPython notebook. Please note that this is hosted on IIITH's Microsoft OneDrive.\n",
    "* ***To run this notebook, download `images` at notebook location and run the notebook***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import os, random\n",
    "import skimage\n",
    "from imageio import imread, imwrite\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.cm as cm\n",
    "import cv2,math\n",
    "import time\n",
    "from imutils import paths\n",
    "import imutils\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib.patches import Ellipse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB to greyscale\n",
    "def rgb2gray(image):\n",
    "    '''\n",
    "    A function that takes in input an image and returns its greyscale version\n",
    "    '''\n",
    "    if (len(image.shape)==2):\n",
    "        return image\n",
    "    elif (len(image.shape)==3):\n",
    "        r = image[:,:,0]\n",
    "        g = image[:,:,1]\n",
    "        b = image[:,:,2]\n",
    "        output = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return output.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "## Image Mosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySIFT(image):\n",
    "    '''\n",
    "    A function to compute SIFT features.\n",
    "    '''\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypointsImage, descriptorImage = sift.detectAndCompute(image,None)\n",
    "    return keypointsImage, descriptorImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoodMatches(descriptorImage1, descriptorImage2, factor = 2):\n",
    "    '''\n",
    "    A funtion to find dense matches using cv2's Brute Force Matcher. The useful matches are sorted using using a \n",
    "    factor of distance.\n",
    "    '''\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptorImage1, descriptorImage2, k=2)\n",
    "    print('No. of matches obtained = ',np.asarray(matches).shape)\n",
    "    goodList = []\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < factor*n.distance:\n",
    "            goodList.append([m])\n",
    "            good.append(m)\n",
    "    return goodList, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInliers(mask, num=10):\n",
    "    '''\n",
    "    A function to obtain good points for drawing the mask.\n",
    "    '''\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    indices = []\n",
    "    for ind in range(len(matchesMask)):\n",
    "        if matchesMask[ind] == 1:\n",
    "            indices.append(ind)\n",
    "    matchesMask = [0]*len(matchesMask)\n",
    "    np.random.shuffle(indices)\n",
    "    indices = indices[:num]\n",
    "    for ind in indices:\n",
    "            matchesMask[ind] = 1\n",
    "    return matchesMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExtremePoints(image1CornersPlane2):\n",
    "    '''\n",
    "    A fumction to find the corners of an input stitched image.\n",
    "    '''\n",
    "    xMin = min(image1CornersPlane2[0][0], image1CornersPlane2[1][0])\n",
    "    yMin = min(image1CornersPlane2[0][1], image1CornersPlane2[3][1])\n",
    "    xMax = max(image1CornersPlane2[2][0], image1CornersPlane2[3][0])\n",
    "    yMax = max(image1CornersPlane2[1][1], image1CornersPlane2[2][1])\n",
    "    return xMin, yMin, xMax, yMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_pano(image1, image2, idx, option = 1):\n",
    "    '''\n",
    "    A function to stitch two images. Inbuilt cv2.findHomography is used.\n",
    "    '''\n",
    "    keypointsImage1, descriptorImage1 = applySIFT(image1)\n",
    "    keypointsImage2, descriptorImage2 = applySIFT(image2)\n",
    "\n",
    "    Image1Keypoints=cv2.drawKeypoints(image1,keypointsImage1,None)\n",
    "    cv2.imwrite('Results/sift1_'+str(idx)+'.jpg',Image1Keypoints)\n",
    "    cv2.imshow('keypoints in Image 1',Image1Keypoints)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    Image2Keypoints=cv2.drawKeypoints(image2,keypointsImage2,None)\n",
    "    cv2.imwrite('Results/sift2_'+str(idx)+'.jpg',Image2Keypoints)\n",
    "    cv2.imshow('keypoints in Image 2',Image2Keypoints)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    goodList, good = getGoodMatches(descriptorImage1, descriptorImage2)\n",
    "\n",
    "    imagePlot = cv2.drawMatchesKnn(image1,keypointsImage1,image2,keypointsImage2,goodList,None,flags=2)\n",
    "    cv2.imwrite('Results/matches_knn_'+str(idx)+'.jpg',imagePlot)\n",
    "    cv2.imshow('matches derived by 2nn',imagePlot)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    ptsImage1 = np.array([ keypointsImage1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    ptsImage2 = np.array([ keypointsImage2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "    H, mask = cv2.findHomography(ptsImage1, ptsImage2, cv2.RANSAC)\n",
    "    print('Homography Matrix:')\n",
    "    print(H)\n",
    " \n",
    "    matchesMask = getInliers(mask, 10)\n",
    "    inlierImage = cv2.drawMatches(image1,keypointsImage1,image2,keypointsImage2,good,None,matchesMask = matchesMask,flags = 2)\n",
    "    cv2.imwrite('Results/matches_'+str(idx)+'.jpg',inlierImage)\n",
    "    cv2.imshow('matches in image 1',inlierImage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if (option == 1):\n",
    "        h, w, d = image1.shape\n",
    "        image1Corners = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "        image1CornersPlane2 = np.squeeze(cv2.perspectiveTransform(image1Corners,H))\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        xMin, yMin, xMax, yMax = getExtremePoints(image1CornersPlane2)\n",
    "        t1 = (xMax-xMin, yMax-yMin)\n",
    "        t2 = (len(image2[0])-int(xMin), len(image2)-int(yMin))\n",
    "        finalImageShape = max(t1,t2)\n",
    "        if xMin < 0 and yMin < 0:\n",
    "            translate = np.float32([[1,0, -xMin], [0,1, -yMin], [0,0,1]])\n",
    "        elif xMin < 0:\n",
    "            translate = np.float32([[1,0, -xMin], [0,1,0], [0,0,1]])\n",
    "        elif xMin < 0:\n",
    "            translate = np.float32([[1,0,0], [0,1, -yMin], [0,0,1]])\n",
    "        else:\n",
    "            translate = np.float32([[1,0,0], [0,1,0], [0,0,1]])\n",
    "        finalImage = cv2.warpPerspective(image1, np.matmul(translate,H), finalImageShape)\n",
    "        finalImage[-int(yMin):-int(yMin)+image2.shape[0], -int(xMin):-int(xMin)+image2.shape[1]]=image2\n",
    "    \n",
    "        cv2.imwrite('Results/uncrop_pano_'+str(idx)+'.jpg',finalImage)\n",
    "        cv2.imshow('Uncropped Pano',finalImage)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        return finalImage\n",
    "    \n",
    "    elif (option == 2):\n",
    "        h1, w1 = image2.shape[:2]\n",
    "        h2, w2 = image1.shape[:2]\n",
    "        c1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "        c2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "        c2_ = cv2.perspectiveTransform(c2, H)\n",
    "        c = np.concatenate((c1, c2_), axis=0)\n",
    "\n",
    "        [xmin, ymin] = np.int32(c.min(axis=0).ravel() - 0.5)\n",
    "        [xmax, ymax] = np.int32(c.max(axis=0).ravel() + 0.5)\n",
    "        t = [-xmin, -ymin]\n",
    "\n",
    "        Ht = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])\n",
    "\n",
    "        out = cv2.warpPerspective(image1, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "        out[t[1]:h1+t[1], t[0]:w1+t[0]] = image2\n",
    "        finalImage = out\n",
    "        cv2.imwrite('Results/uncrop_pano_'+str(idx)+'.jpg',finalImage)\n",
    "        cv2.imshow('Uncropped Pano',finalImage)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return finalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(im, scale_percent):\n",
    "    '''\n",
    "    A function to resize images for fast computation.\n",
    "    '''\n",
    "    width = int(im.shape[1] * scale_percent / 100)\n",
    "    height = int(im.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    im = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scottsdale1=cv2.imread('./images/image_mosaicing/img3_1.png')\n",
    "scottsdale2=cv2.imread('./images/image_mosaicing/img3_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (2240, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.92319108e+00 -6.88267538e-02 -1.04475782e+03]\n",
      " [ 3.45715051e-01  1.69035404e+00 -2.94587475e+02]\n",
      " [ 9.20503413e-04  3.27063438e-05  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [40, 48, 52],\n",
       "        ...,\n",
       "        [56, 65, 87],\n",
       "        [54, 66, 84],\n",
       "        [52, 66, 84]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [40, 49, 53],\n",
       "        ...,\n",
       "        [52, 63, 84],\n",
       "        [51, 64, 82],\n",
       "        [51, 65, 83]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [46, 56, 59],\n",
       "        ...,\n",
       "        [50, 61, 82],\n",
       "        [52, 66, 84],\n",
       "        [54, 69, 86]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano(scottsdale1, scottsdale2, 'scottsdale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "amphi1 = resize(cv2.imread('./images/image_mosaicing/img1_1.jpg'), 40)\n",
    "amphi2 = resize(cv2.imread('./images/image_mosaicing/img1_2.jpg'), 40)\n",
    "amphi3 = resize(cv2.imread('./images/image_mosaicing/img1_3.jpg'), 40)\n",
    "amphi4 = resize(cv2.imread('./images/image_mosaicing/img1_4.jpg'), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (9587, 2)\n",
      "Homography Matrix:\n",
      "[[ 6.16890885e-01  2.81961166e-01 -9.98020144e+01]\n",
      " [-5.52838076e-02  1.01497193e+00  7.10301999e+01]\n",
      " [-9.78068275e-05  2.69342591e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (1275, 2)\n",
      "Homography Matrix:\n",
      "[[ 3.62179765e+00 -3.92186273e-02 -7.65341672e+02]\n",
      " [ 2.66623075e-01  3.18800185e+00 -1.78543408e+02]\n",
      " [ 5.97486549e-04 -2.47070773e-05  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [41, 50, 54],\n",
       "        [40, 49, 53],\n",
       "        [39, 48, 51]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [40, 49, 52],\n",
       "        [39, 48, 52],\n",
       "        [41, 50, 53]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [41, 50, 53],\n",
       "        [40, 49, 52],\n",
       "        [33, 42, 45]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano(amphi1, amphi2, 'amphi12')\n",
    "amphi_temp_1 = resize(cv2.imread('./Results/uncrop_pano_amphi12.jpg'), 40)\n",
    "stitch_pano(amphi_temp_1, amphi3, 'amphi123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (2189, 2)\n",
      "Homography Matrix:\n",
      "[[ 3.12337235e+00 -3.18927270e-02 -1.33055870e+03]\n",
      " [ 1.73684197e-01  2.85082939e+00 -3.26523634e+02]\n",
      " [ 3.90178218e-04  3.79041495e-06  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [137, 143, 151],\n",
       "        [136, 143, 151],\n",
       "        [133, 139, 147]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [135, 142, 151],\n",
       "        [135, 142, 151],\n",
       "        [133, 140, 149]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [136, 144, 154],\n",
       "        [137, 145, 155],\n",
       "        [132, 141, 151]]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amphi_temp_2 = resize(cv2.imread('./Results/uncrop_pano_amphi123.jpg'), 40)\n",
    "stitch_pano(amphi_temp_2, amphi4, 'amphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "him1 = resize(cv2.imread('./images/image_mosaicing/img5_1.jpg'), 40)\n",
    "him2 = resize(cv2.imread('./images/image_mosaicing/img5_2.jpg'), 40)\n",
    "him3 = resize(cv2.imread('./images/image_mosaicing/img5_3.jpg'), 40)\n",
    "him4 = resize(cv2.imread('./images/image_mosaicing/img5_4.jpg'), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (7210, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.46336981e+00  1.21535145e-01 -6.96334131e+02]\n",
      " [ 6.91326360e-02  1.37126729e+00 -6.63710655e+02]\n",
      " [ 1.79062737e-04  2.11533310e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (3933, 2)\n",
      "Homography Matrix:\n",
      "[[ 2.22365120e+00 -2.97467051e-01 -5.34705248e+02]\n",
      " [-1.99367500e-02  1.99736654e+00 -1.36564799e+02]\n",
      " [ 1.07259314e-05 -3.56937482e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (4243, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.56981163e+00  5.85740058e-01 -1.57655495e+02]\n",
      " [-2.49983003e-01  2.14304581e+00 -3.62734488e+02]\n",
      " [-4.32920256e-04  3.43929103e-04  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano(him1, him3, 'him13')\n",
    "him_temp_1 = resize(cv2.imread('./Results/uncrop_pano_him13.jpg'), 40)\n",
    "stitch_pano(him_temp_1, him2, 'him132')\n",
    "him_temp_2 = resize(cv2.imread('./Results/uncrop_pano_him132.jpg'), 40)\n",
    "stitch_pano(him_temp_2, him4, 'him')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = cv2.imread('./images/image_mosaicing/img2_1.png')\n",
    "tm2 = cv2.imread('./images/image_mosaicing/img2_2.png')\n",
    "tm3 = cv2.imread('./images/image_mosaicing/img2_3.png')\n",
    "tm4 = cv2.imread('./images/image_mosaicing/img2_4.png')\n",
    "tm5 = cv2.imread('./images/image_mosaicing/img2_5.png')\n",
    "tm6 = cv2.imread('./images/image_mosaicing/img2_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (1486, 2)\n",
      "Homography Matrix:\n",
      "[[ 9.99941080e-01 -4.11363788e-05 -1.82984265e+02]\n",
      " [ 2.53608849e-05  9.99840331e-01 -9.98903910e+00]\n",
      " [-5.16090160e-08 -1.99081949e-07  1.00000000e+00]]\n",
      "No. of matches obtained =  (1851, 2)\n",
      "Homography Matrix:\n",
      "[[ 9.99912560e-01 -7.11784232e-05 -4.74948114e+02]\n",
      " [-2.80470480e-05  9.99889004e-01  2.01577202e+00]\n",
      " [-1.12005610e-07 -1.08132909e-07  1.00000000e+00]]\n",
      "No. of matches obtained =  (906, 2)\n",
      "Homography Matrix:\n",
      "[[ 9.99507867e-01 -4.22715444e-04 -4.92067519e+00]\n",
      " [ 2.15426866e-05  9.98893271e-01  1.39044213e+02]\n",
      " [-3.22899526e-07 -2.24681395e-06  1.00000000e+00]]\n",
      "No. of matches obtained =  (2372, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.00005632e+00  1.29784643e-04 -1.01042327e+02]\n",
      " [-2.65147963e-05  9.99836977e-01 -2.20935942e+02]\n",
      " [ 1.50775295e-08  1.64230798e-07  1.00000000e+00]]\n",
      "No. of matches obtained =  (3228, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.00029210e+00  9.77813295e-05 -4.26155505e+02]\n",
      " [-1.00419651e-05  1.00029507e+00 -2.45065451e+02]\n",
      " [ 1.65015551e-07  5.37947825e-07  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "tmf = stitch_pano(stitch_pano(stitch_pano(tm4,stitch_pano(stitch_pano(tm1,tm2,idx = 'tm_temp12',option =2),tm3,idx = 'tm_temp123',option =2),idx = 'tm_temp4123',option =2),tm5,idx = 'tm_temp41235',option =2),tm6,idx = 'tm',option =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "room1 = cv2.imread('./images/image_mosaicing/im1.jpg')\n",
    "room2 = cv2.imread('./images/image_mosaicing/im2.jpg')\n",
    "room3 = cv2.imread('./images/image_mosaicing/im3.jpg')\n",
    "room4 = cv2.imread('./images/image_mosaicing/im4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (18225, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.25600637e+00 -1.29018181e-01 -1.72791209e+03]\n",
      " [-2.25727332e-02  1.13118090e+00  9.89540862e+01]\n",
      " [ 7.95126048e-05 -6.88014735e-05  1.00000000e+00]]\n",
      "No. of matches obtained =  (21160, 2)\n",
      "Homography Matrix:\n",
      "[[-3.94255643e-01  3.54495040e+00  1.22889973e+03]\n",
      " [-7.43799130e-01  1.58473823e+01  1.37615621e+03]\n",
      " [-4.33918570e-04  7.46981234e-03  1.00000000e+00]]\n",
      "No. of matches obtained =  (11006, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.43423647e+00  5.16673581e-02 -1.90091006e+03]\n",
      " [ 4.40426729e-02  1.29317179e+00 -1.33290775e+02]\n",
      " [ 9.14301773e-05  4.07347504e-06  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "room_pano = stitch_pano(stitch_pano(stitch_pano(room1,room2,idx = 'room12',option = 2),room3, idx = 'room123',option = 2),room4,idx = 'room',option = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panorama Stitching using Homography from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(pts1,pts2):\n",
    "    '''\n",
    "    A function to compute the homography matrix based on previous work in DLT\n",
    "    '''\n",
    "    pt1 = np.insert(pts1,2,1,axis=1)\n",
    "    wp = np.stack((pt1,pt1),2).transpose(0,2,1).reshape(2*pt1.shape[0],3)\n",
    "    wp_mat = np.hstack((wp,wp,wp))\n",
    "    tmp_mat = np.tile(np.hstack((np.vstack((-1*np.ones(3),np.zeros(3))),np.vstack((np.zeros(3),-1*np.ones(3))))),(pts2.shape[0],1))\n",
    "    im_mat = np.hstack((tmp_mat,np.tile(pts2.ravel()[:,None],(1,3))))\n",
    "    A = im_mat*wp_mat\n",
    "    \n",
    "    U,D,V = np.linalg.svd(A)\n",
    "    h = V[-1,:]\n",
    "    H = h.reshape(3,3)\n",
    "    return H/H[2,2]\n",
    "\n",
    "def error(pts1,pts2,M):\n",
    "    '''\n",
    "    A function to compute reprojection error.\n",
    "    '''\n",
    "    proj_pts = M.dot(np.insert(pts1,2,1,axis=1).T)\n",
    "    proj_pts = (proj_pts/proj_pts[-1,:])[:2,:].T\n",
    "    return np.sum(np.linalg.norm(proj_pts-pts2,axis=1))/pts1.shape[0]\n",
    "\n",
    "def ransac_homography(pts1,pts2,sample_sz = 30,max_iter=1000):\n",
    "    '''\n",
    "    A function to compute the homography matrix and optimises the matrix based on running RANSAC for a \n",
    "    smaller set of points.\n",
    "    '''\n",
    "    errr = 1e6\n",
    "    H0 = np.empty((3,3))\n",
    "    for i in range(max_iter):\n",
    "        ind = np.random.choice(pts1.shape[0],sample_sz,replace = False)\n",
    "        pt1 = pts1[ind,:]\n",
    "        pt2 = pts2[ind,:]\n",
    "        H = homography(pt1,pt2)\n",
    "        err = error(pt1,pt2,H)\n",
    "        if(err<errr):\n",
    "            errr = err\n",
    "            H0 = H\n",
    "    return H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_pano_self(image1, image2, idx, option = 1, factor = 2):\n",
    "    '''\n",
    "    Stitch two input images based on RANSAC based homography matrix.\n",
    "    '''\n",
    "    keypointsImage1, descriptorImage1 = applySIFT(image1)\n",
    "    keypointsImage2, descriptorImage2 = applySIFT(image2)\n",
    "\n",
    "    Image1Keypoints=cv2.drawKeypoints(image1,keypointsImage1,None)\n",
    "    cv2.imwrite('Results/self/sift1_'+str(idx)+'.jpg',Image1Keypoints)\n",
    "    cv2.imshow('keypoints in Image 1',Image1Keypoints)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    Image2Keypoints=cv2.drawKeypoints(image2,keypointsImage2,None)\n",
    "    cv2.imwrite('Results/self/sift2_'+str(idx)+'.jpg',Image2Keypoints)\n",
    "    cv2.imshow('keypoints in Image 2',Image2Keypoints)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    goodList, good = getGoodMatches(descriptorImage1, descriptorImage2, factor=factor)\n",
    "\n",
    "    imagePlot = cv2.drawMatchesKnn(image1,keypointsImage1,image2,keypointsImage2,goodList,None,flags=2)\n",
    "    cv2.imwrite('Results/self/matches_knn_'+str(idx)+'.jpg',imagePlot)\n",
    "    cv2.imshow('matches derived by 2nn',imagePlot)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    ptsImage1 = np.array([ keypointsImage1[m.queryIdx].pt for m in good]).reshape(-1,2)\n",
    "    ptsImage2 = np.array([ keypointsImage2[m.trainIdx].pt for m in good]).reshape(-1,2)\n",
    "\n",
    "    H = ransac_homography(ptsImage1, ptsImage2)\n",
    "    print('Homography Matrix:')\n",
    "    print(H)\n",
    "    \n",
    "    if (option == 1):\n",
    "        h, w, d = image1.shape\n",
    "        image1Corners = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "        image1CornersPlane2 = np.squeeze(cv2.perspectiveTransform(image1Corners,H))\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        xMin, yMin, xMax, yMax = getExtremePoints(image1CornersPlane2)\n",
    "        t1 = (xMax-xMin, yMax-yMin)\n",
    "        t2 = (len(image2[0])-int(xMin), len(image2)-int(yMin))\n",
    "        finalImageShape = max(t1,t2)\n",
    "        if xMin < 0 and yMin < 0:\n",
    "            translate = np.float32([[1,0, -xMin], [0,1, -yMin], [0,0,1]])\n",
    "        elif xMin < 0:\n",
    "            translate = np.float32([[1,0, -xMin], [0,1,0], [0,0,1]])\n",
    "        elif xMin < 0:\n",
    "            translate = np.float32([[1,0,0], [0,1, -yMin], [0,0,1]])\n",
    "        else:\n",
    "            translate = np.float32([[1,0,0], [0,1,0], [0,0,1]])\n",
    "        finalImage = cv2.warpPerspective(image1, np.matmul(translate,H), finalImageShape)\n",
    "        finalImage[-int(yMin):-int(yMin)+image2.shape[0], -int(xMin):-int(xMin)+image2.shape[1]]=image2\n",
    "    \n",
    "        cv2.imwrite('Results/self/uncrop_pano_'+str(idx)+'.jpg',finalImage)\n",
    "        cv2.imshow('Uncropped Pano',finalImage)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        return finalImage\n",
    "    \n",
    "    elif (option == 2):\n",
    "        h1, w1 = image2.shape[:2]\n",
    "        h2, w2 = image1.shape[:2]\n",
    "        c1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "        c2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "        c2_ = cv2.perspectiveTransform(c2, H)\n",
    "        c = np.concatenate((c1, c2_), axis=0)\n",
    "\n",
    "        [xmin, ymin] = np.int32(c.min(axis=0).ravel() - 0.5)\n",
    "        [xmax, ymax] = np.int32(c.max(axis=0).ravel() + 0.5)\n",
    "        t = [-xmin, -ymin]\n",
    "\n",
    "        Ht = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])\n",
    "\n",
    "        out = cv2.warpPerspective(image1, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "        out[t[1]:h1+t[1], t[0]:w1+t[0]] = image2\n",
    "        finalImage = out\n",
    "        cv2.imwrite('Results/self/uncrop_pano_'+str(idx)+'.jpg',finalImage)\n",
    "        cv2.imshow('Uncropped Pano',finalImage)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return finalImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (2240, 2)\n",
      "Homography Matrix:\n",
      "[[ 2.49056273e+00 -1.14195603e-01 -1.36320001e+03]\n",
      " [ 5.54331296e-01  2.12058950e+00 -4.70892586e+02]\n",
      " [ 1.48498666e-03 -1.06105544e-05  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [56, 65, 87],\n",
       "        [54, 66, 84],\n",
       "        [52, 66, 84]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [52, 63, 84],\n",
       "        [51, 64, 82],\n",
       "        [51, 65, 83]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [50, 61, 82],\n",
       "        [52, 66, 84],\n",
       "        [54, 69, 86]]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano_self(scottsdale1, scottsdale2, 'scottsdale', option = 1, factor=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (9587, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.72275271e+00  4.02524702e-03 -1.04179886e+03]\n",
      " [ 1.76598323e-01  1.47115271e+00 -2.34243686e+02]\n",
      " [ 3.90719391e-04  2.44463586e-05  1.00000000e+00]]\n",
      "No. of matches obtained =  (4306, 2)\n",
      "Homography Matrix:\n",
      "[[ 4.65024490e+00 -7.18000276e-02 -2.72644227e+03]\n",
      " [ 3.41386798e-01  4.07657872e+00 -6.76343109e+02]\n",
      " [ 7.69163812e-04 -5.12789168e-05  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [41, 50, 54],\n",
       "        [40, 49, 53],\n",
       "        [39, 48, 51]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [40, 49, 52],\n",
       "        [39, 48, 52],\n",
       "        [41, 50, 53]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [41, 50, 53],\n",
       "        [40, 49, 52],\n",
       "        [33, 42, 45]]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano_self(amphi1, amphi2, 'amphi12',option=1, factor=0.75)\n",
    "amphi_temp_1 = resize(cv2.imread('./Results/self/uncrop_pano_amphi12.jpg'), 40)\n",
    "stitch_pano_self(amphi_temp_1, amphi3, 'amphi123',option=1, factor=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (8029, 2)\n",
      "Homography Matrix:\n",
      "[[ 4.34737937e+00 -3.61502096e-02 -5.37702096e+03]\n",
      " [ 2.33436516e-01  3.99969650e+00 -1.43749789e+03]\n",
      " [ 5.15043612e-04  1.41828482e-05  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [137, 143, 151],\n",
       "        [136, 143, 151],\n",
       "        [133, 139, 147]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [135, 142, 151],\n",
       "        [135, 142, 151],\n",
       "        [133, 140, 149]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [136, 144, 154],\n",
       "        [137, 145, 155],\n",
       "        [132, 141, 151]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amphi_temp_2 = resize(cv2.imread('./Results/self/uncrop_pano_amphi123.jpg'), 40)\n",
    "stitch_pano_self(amphi_temp_2, amphi4, 'amphi', option=1, factor=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (7210, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.45199464e+00  1.18788786e-01 -6.89276980e+02]\n",
      " [ 6.83203826e-02  1.36000348e+00 -6.57569208e+02]\n",
      " [ 1.75361492e-04  2.03571997e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (3933, 2)\n",
      "Homography Matrix:\n",
      "[[ 2.22710077e+00 -2.95705682e-01 -5.35819832e+02]\n",
      " [-1.95401701e-02  2.00252687e+00 -1.37576855e+02]\n",
      " [ 1.17749662e-05 -3.53990159e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (4243, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.55636675e+00  5.70095639e-01 -1.51410890e+02]\n",
      " [-2.49128542e-01  2.12507502e+00 -3.59076518e+02]\n",
      " [-4.34322564e-04  3.27666401e-04  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stitch_pano_self(him1, him3, 'him13',option=1, factor=0.75)\n",
    "him_temp_1 = resize(cv2.imread('./Results/uncrop_pano_him13.jpg'), 40)\n",
    "stitch_pano_self(him_temp_1, him2, 'him132',option=1, factor=0.75)\n",
    "him_temp_2 = resize(cv2.imread('./Results/uncrop_pano_him132.jpg'), 40)\n",
    "stitch_pano_self(him_temp_2, him4, 'him',option=1, factor=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = cv2.imread('./images/image_mosaicing/img2_1.png')\n",
    "tm2 = cv2.imread('./images/image_mosaicing/img2_2.png')\n",
    "tm3 = cv2.imread('./images/image_mosaicing/img2_3.png')\n",
    "tm4 = cv2.imread('./images/image_mosaicing/img2_4.png')\n",
    "tm5 = cv2.imread('./images/image_mosaicing/img2_5.png')\n",
    "tm6 = cv2.imread('./images/image_mosaicing/img2_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (1486, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.00000000e+00 -3.92972031e-09 -1.83000000e+02]\n",
      " [ 5.28042998e-09  9.99999984e-01 -1.00000001e+01]\n",
      " [ 2.26865896e-11 -6.53728731e-11  1.00000000e+00]]\n",
      "No. of matches obtained =  (1851, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.00000034e+00  1.61176434e-08 -4.75000180e+02]\n",
      " [ 8.98146654e-08  1.00000025e+00  1.99994465e+00]\n",
      " [ 3.18350527e-10  2.05279801e-10  1.00000000e+00]]\n",
      "No. of matches obtained =  (906, 2)\n",
      "Homography Matrix:\n",
      "[[ 9.99999921e-01 -2.15011020e-08 -4.99999425e+00]\n",
      " [-6.55185810e-08  9.99999965e-01  1.39000000e+02]\n",
      " [-1.71356966e-10 -1.65654825e-10  1.00000000e+00]]\n",
      "No. of matches obtained =  (2361, 2)\n",
      "Homography Matrix:\n",
      "[[ 9.99999981e-01  3.16975033e-08 -1.01000003e+02]\n",
      " [-8.42010381e-09  1.00000007e+00 -2.21000019e+02]\n",
      " [-8.09050723e-11  1.58598356e-10  1.00000000e+00]]\n",
      "No. of matches obtained =  (3225, 2)\n",
      "Homography Matrix:\n",
      "[[ 1.00000011e+00  1.55464464e-08 -4.26000055e+02]\n",
      " [ 9.40094707e-09  1.00000024e+00 -2.45000071e+02]\n",
      " [-2.62806351e-11  4.19580126e-10  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "tmf = stitch_pano_self(stitch_pano_self(stitch_pano_self(tm4,stitch_pano_self(stitch_pano_self(tm1,tm2,idx = 'tm_temp12',option =2, factor = 0.75),tm3,idx = 'tm_temp123',option =2, factor = 0.75),idx = 'tm_temp4123',option =2, factor = 0.75),tm5,idx = 'tm_temp41235',option =2, factor = 0.75),tm6,idx = 'tm',option =2, factor = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "room1 = cv2.imread('./images/image_mosaicing/im1.jpg')\n",
    "room2 = cv2.imread('./images/image_mosaicing/im2.jpg')\n",
    "room3 = cv2.imread('./images/image_mosaicing/im3.jpg')\n",
    "room4 = cv2.imread('./images/image_mosaicing/im4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matches obtained =  (18225, 2)\n",
      "Homography Matrix:\n",
      "[[-5.28388839e-01 -2.05333653e-01  1.43443054e+03]\n",
      " [-2.77638916e-01 -6.22344602e-02  7.29653367e+02]\n",
      " [-3.39783591e-04 -2.41140134e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (18915, 2)\n",
      "Homography Matrix:\n",
      "[[-4.43853499e-01 -1.50754472e-01  9.65102146e+02]\n",
      " [-7.56899334e-01 -3.23479157e-01  1.83908041e+03]\n",
      " [-4.00643478e-04 -1.83317943e-04  1.00000000e+00]]\n",
      "No. of matches obtained =  (11006, 2)\n",
      "Homography Matrix:\n",
      "[[-6.07631764e-01 -7.02570392e-01  2.47604204e+03]\n",
      " [-5.16189966e-01 -5.40771653e-01  1.98812318e+03]\n",
      " [-2.47497400e-04 -2.76706145e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "room_pano = stitch_pano_self(stitch_pano_self(stitch_pano_self(room1,room2,idx = 'room12',option = 2),room3, idx = 'room123',option = 2),room4,idx = 'room',option = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Think of an algorithm which can stitch images given in any order without human\n",
    "intervention? If yes, modify your exisitng code accordingly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is it possible to stitch a panorama without human intervention, given noisy images\n",
    "which do not belong to the same scene? If yes, how?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "## Stereo Correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(v1,v2):\n",
    "    '''\n",
    "    A function that computes correlation between pixels.\n",
    "    '''\n",
    "    return v1.T.dot(v2)/(np.sqrt(v1.T.dot(v1))*np.sqrt(v2.T.dot(v2)))\n",
    "\n",
    "def correlation_matching(img1,img2,window_size=45,stride=45):\n",
    "    '''\n",
    "    A function that computes correlation between pixels and stores the pixels with best matches.\n",
    "    '''\n",
    "    h1,w1,c = img1.shape\n",
    "    h2,w2,c = img2.shape\n",
    "    \n",
    "#     Pass through all the patches in img1 and find patch in img2 with least \n",
    "    best_matches = []\n",
    "    for y1 in range(0,h1-window_size,stride):\n",
    "        for x1 in range(0,w1-window_size,stride):\n",
    "            least_dis = 4.0\n",
    "            for y2 in range(0,h2-window_size,stride):\n",
    "                for x2 in range(0,w2-window_size,stride):\n",
    "                    v1 = img1[y1:y1+window_size, x1:x1+window_size,:].flatten()\n",
    "                    v2 = img2[y2:y2+window_size, x2:x2+window_size,:].flatten()\n",
    "                    dis = corr(v1,v2)\n",
    "                    if least_dis > dis:\n",
    "                        least_dis = dis\n",
    "                        least_coord = [x1,y1,x2,y2,dis]\n",
    "            best_matches.append(least_coord)\n",
    "    return best_matches\n",
    "\n",
    "def draw_matches(img,matches,window_size=128):\n",
    "    '''\n",
    "    A helper function to draw the matches stored in above function.\n",
    "    '''\n",
    "    h,w,c = img.shape\n",
    "    for match in matches:\n",
    "        pt1 = (match[1]+window_size//2,match[0]+window_size//2)\n",
    "        pt2 = (match[3]+window_size//2+w//2,match[2]+ window_size//2)\n",
    "        line_img = cv2.line(img,pt1,pt2,(0,0,225),3)\n",
    "    \n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumyasis/.virtualenvs/cvit1/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./images/stereo_images/1.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "matches = correlation_matching(img1,img2)\n",
    "dis_im = draw_matches(img,matches)\n",
    "cv2.imwrite('./Results/q2/Dense_Pair1.jpg',dis_im)\n",
    "cv2.imshow('Dense Pair',dis_im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Case 2\n",
    "img = cv2.imread('./images/stereo_images/2.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "matches = correlation_matching(img1,img2)\n",
    "dis_im = draw_matches(img,matches)\n",
    "cv2.imwrite('./Results/q2/Dense_Pair2.jpg',dis_im)\n",
    "cv2.imshow('Dense Pair',dis_im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Case 3\n",
    "img = cv2.imread('./images/stereo_images/3.jpeg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "matches = correlation_matching(img1,img2)\n",
    "dis_im = draw_matches(img,matches)\n",
    "cv2.imwrite('./Results/q2/Dense_Pair3.jpg',dis_im)\n",
    "cv2.imshow('Dense Pair',dis_im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dynamic time Warping to find matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' \n",
    "    A function to draw the epilines for the points in image 2 on image 1 \n",
    "    where input lines are the corresponding epilines\n",
    "    '''\n",
    "    r,c,_ = img1.shape\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "def dp_(line1, line2):\n",
    "    dp = np.zeros((line1.shape[0]+1,line2.shape[0]+1))\n",
    "    \n",
    "    for i,x in enumerate(line1):\n",
    "        for j,y in enumerate(line2):\n",
    "            if(i==0 or j==0):\n",
    "                continue\n",
    "            elif (line1[i-1] == line1[j-1]): \n",
    "                dp[i,j] = 1 + dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i,j] = max(dp[i-1,j], dp[i,j-1])\n",
    "\n",
    "    i = line1.shape[0], j = line2.shape[0]; \n",
    "    newline = np.zeros(line1.shape[0])\n",
    "    index = line1.shape[0]\n",
    "    while (i > 0 and j > 0) : \n",
    "        if (line1[i-1] == line2[j-1]): \n",
    "            newline[index-1] = line1[i-1]\n",
    "            i-=1\n",
    "            j-=1\n",
    "            index-=1 \n",
    "      \n",
    "        elif (dp[i-1,j] > dp[i,j-1]): \n",
    "            i-=1 \n",
    "        else:\n",
    "            j-=1\n",
    "    return newline\n",
    "\n",
    "def plot_epipolar_lines(img1,img2,sift_params,idx,match_th =0.8):\n",
    "    '''\n",
    "    A function to draw the epipolar lines with the best matches on those lines. \n",
    "    '''\n",
    "    kp1,des1,kp2,des2,_,_ = sift_params\n",
    "    index_params = dict(algorithm = 1, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < match_th*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.RANSAC)\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "    lines1 = lines1.reshape(-1,3)\n",
    "    img3,img4 = drawlines(img1,img2,lines1,pts1,pts2)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "    lines2 = lines2.reshape(-1,3)\n",
    "    img5,img6 = drawlines(img2,img1,lines2,pts2,pts1)\n",
    "    \n",
    "    cv2.imwrite('./Results/q2/Parallel epilines img1_'+str(idx)+'.jpg',img5)\n",
    "    cv2.imwrite('./Results/q2/Parallel epilines img2_'+str(idx)+'.jpg',img6)\n",
    "    cv2.imshow('Epiline img 1',img5)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imshow('Epiline img 2',img6)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return lines1,lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/1.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 1)\n",
    "l1,l2 = plot_epipolar_lines(img1,img2,sift_param, idx = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/2.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 2)\n",
    "l1, l2 = plot_epipolar_lines(img1,img2,sift_param,idx = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/3.jpeg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2, idx = 3)\n",
    "l1,l2 = plot_epipolar_lines(img1,img2,sift_param, idx =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Epilines on stereo rectified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_sift_matching(img1,img2,idx,min_match_cnt=500):\n",
    "    '''\n",
    "    A function to derive sift features and run a brute force match to find correspondences\n",
    "    '''\n",
    "    cv2.imshow('Image 1',img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imshow('Image 2',img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    h,w,c = img1.shape\n",
    "    kp=[]\n",
    "    for i in range(1,h,10):\n",
    "        for j in range(1,w,10):\n",
    "            kp.append(cv2.KeyPoint(i, j, 3))\n",
    "    \n",
    "    gray_im1 = cv2.cvtColor(img1,cv2.COLOR_RGB2GRAY)\n",
    "    kp1,des1 = sift.compute(gray_im1,kp)\n",
    "\n",
    "    gray_im2 = cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY)\n",
    "    kp2,des2 = sift.compute(gray_im2,kp)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "    matches = bf.match(des1,des2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)[0:min_match_cnt]\n",
    "    draw_params = dict(matchesMask=None,singlePointColor=None,flags=2)\n",
    "        \n",
    "    dis_im = cv2.drawMatches(img1,kp1,img1,kp1,matches,None,**draw_params)\n",
    "    cv2.imshow('Matches',dis_im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return kp1,des1,kp2,des2,matches,dis_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_rectification(img1,img2,sift_params,match_th =0.8):\n",
    "    '''\n",
    "    A function that uses sift features to rectify two input images\n",
    "    i.e. make the epilines parallel in both images to greedily or using dp verify the\n",
    "    match.\n",
    "    '''\n",
    "    kp1,des1,kp2,des2,_,_ = sift_params\n",
    "    \n",
    "    index_params = dict(algorithm = 1, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < match_th*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    \n",
    "    F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.RANSAC)\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "    img_size = img1.shape[0:2]\n",
    "    p,H1,H2=cv2.stereoRectifyUncalibrated(pts1, pts2, F, img_size)\n",
    "        \n",
    "    H3= H1.dot(H2)\n",
    "    img1_corrected = cv2.warpPerspective(img1, H1, img_size)\n",
    "    img2_corrected = cv2.warpPerspective(img2, H3, img_size)\n",
    "    \n",
    "    return img1_corrected, img2_corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/1.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 1)\n",
    "rect_img1, rect_img2 = stereo_rectification(img1,img2,sift_param,match_th =0.8)\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect1_1.jpg',rect_img1)\n",
    "cv2.imshow('Stereo Rectified image 1',rect_img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect1_2.jpg',rect_img2)\n",
    "cv2.imshow('Stereo Rectified image 2',rect_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/2.jpg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2, idx = 2)\n",
    "rect_img1, rect_img2 = stereo_rectification(img1,img2,sift_param,match_th =0.8)\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect2_1.jpg',rect_img1)\n",
    "cv2.imshow('Stereo Rectified image 1',rect_img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect2_2.jpg',rect_img2)\n",
    "cv2.imshow('Stereo Rectified image 2',rect_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/stereo_images/3.jpeg')\n",
    "h,w,c = img.shape\n",
    "img1 = img[:,0:w//2,:]\n",
    "img2 = img[:,w//2:w,:]\n",
    "sift_param = dense_sift_matching(img1,img2, idx = 3)\n",
    "rect_img1, rect_img2 = stereo_rectification(img1,img2,sift_param,match_th =1.1)\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect3_1.jpg',rect_img1)\n",
    "cv2.imshow('Stereo Rectified image 1',rect_img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('./Results/q2/Stereo_Rect3_2.jpg',rect_img2)\n",
    "cv2.imshow('Stereo Rectified image 2',rect_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./Results/q2/Stereo_Rect1_1.jpg')\n",
    "img2 = cv2.imread('./Results/q2/Stereo_Rect1_2.jpg')\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 'rect1')\n",
    "l1,l2 = plot_epipolar_lines(img1,img2,sift_param, idx = 'rect1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./Results/q2/Stereo_Rect2_1.jpg')\n",
    "img2 = cv2.imread('./Results/q2/Stereo_Rect2_2.jpg')\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 'rect2')\n",
    "l1,l2 = plot_epipolar_lines(img1,img2,sift_param, idx = 'rect2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./Results/q2/Stereo_Rect3_1.jpg')\n",
    "img2 = cv2.imread('./Results/q2/Stereo_Rect3_2.jpg')\n",
    "sift_param = dense_sift_matching(img1,img2,idx = 'rect3')\n",
    "l1,l2 = plot_epipolar_lines(img1,img2,sift_param, idx = 'rect3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
